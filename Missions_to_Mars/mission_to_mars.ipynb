{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to choose the executable path\n",
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": ChromeDriverManager().install()}\n",
    "    return Browser(\"chrome\", **executable_path, headless = False, user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.54 Safari/537.36\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Browser\n",
    "browser = init_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit to Mars News Site\n",
    "mars_news_url = \"http://redplanetscience.com\"\n",
    "browser.visit(mars_news_url)\n",
    "\n",
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "news_soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the latest article's title\n",
    "news_title = news_soup.find(\"div\", class_ = \"content_title\")\n",
    "news_title = news_title.text.strip()\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the latest article's paragraph\n",
    "news_paragraph = news_soup.find(\"div\", class_ = \"article_teaser_body\")\n",
    "news_paragraph = news_paragraph.text.strip()\n",
    "print(news_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set connection to website for JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the image URL\n",
    "mars_featured_image_url = \"http://spaceimages-mars.com/\"\n",
    "browser.visit(mars_featured_image_url)\n",
    "\n",
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "image_soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the full url string to a variable called \"featured_image_url\"\n",
    "featured_image = image_soup.find(\"img\", class_ = \"headerimage fade-in\")\n",
    "featured_image_url = mars_featured_image_url + featured_image[\"src\"]\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set connection to get Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for Mars Facts\n",
    "mars_facts_url = \"http://space-facts.com/mars/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to convert the data to a HTML table string\n",
    "mars_facts = pd.read_html(mars_facts_url)\n",
    "\n",
    "# Save as DataFrame\n",
    "mars_facts_df = pd.DataFrame(mars_facts[1])\n",
    "\n",
    "mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to html\n",
    "mars_facts_df.to_html(\"Resources/mars_facts.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to HTML string\n",
    "mars_facts = mars_facts_df.to_html(header = True, index = True)\n",
    "pprint(mars_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url for Mars Hemisphere\n",
    "mars_hemispheres_url = \"http://marshemispheres.com/\"\n",
    "browser.visit(mars_hemispheres_url)\n",
    "\n",
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "hemispheres_soup = bs(html, \"html.parser\")\n",
    "\n",
    "# Each link is located in \"div\" tag, class \"description\"\n",
    "# Find all elements and store in variable\n",
    "hems_url = hemispheres_soup.find_all(\"div\", class_ = \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list for each URL\n",
    "hemis_url = []\n",
    "\n",
    "for hem in hems_url:\n",
    "    \n",
    "    hem_url = hem.find(\"a\")[\"href\"]\n",
    "    hemis_url.append(hem_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dictionaries called hemisphere_image_urls\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Iterate through all URLs saved in hemis_url\n",
    "for hemi in hemis_url:\n",
    "    \n",
    "    mars_hem_url = mars_hemispheres_url + hemi\n",
    "    print(mars_hem_url)\n",
    "    \n",
    "    # Visit to Hemisphere\n",
    "    browser.visit(mars_hem_url)\n",
    "    \n",
    "    # HTML Object\n",
    "    html = browser.html\n",
    "\n",
    "    # Parse HTML with Beautiful Soup\n",
    "    hemi_soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # Locate each title and save to raw_title, to be cleaned\n",
    "    raw_title = hemi_soup.find(\"h2\", class_ = \"title\").text\n",
    "    \n",
    "    # Remove \" Enhanced\" tag text from each \"title\" via split on \" Enhanced\"\n",
    "    title = raw_title.split(\" Enhanced\")[0]\n",
    "    \n",
    "    # Locate each full resolution image for all 4 Hemisphere URLs\n",
    "    img_url = hemi_soup.find(\"img\", class_ = \"wide-image\")[\"src\"]\n",
    "    \n",
    "    # Append title and img_url to \"hemisphere_image_url\"\n",
    "    hemisphere_image_urls.append({\"title\": title, \"img_url\": mars_hemispheres_url + img_url})\n",
    "\n",
    "# Exit Browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the return value in Mongo as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for all Mars Data.\n",
    "mars_db = {}\n",
    "\n",
    "# Append news_title and news_paragraph to mars_data\n",
    "mars_db[\"news_title\"] = news_title\n",
    "mars_db[\"news_paragraph\"] = news_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append featured_image_url to mars_data.\n",
    "mars_db[\"featured_image_url\"] = featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append mars_facts to mars_data.\n",
    "mars_db[\"mars_facts\"] = mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append hemisphere_image_urls to mars_data.\n",
    "mars_db[\"hemisphere_image_urls\"] = hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(mars_db)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cba033dbfb308e6ef82904202bf1aac94d65a342a0fa0b8648c060ba2fe22e31"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
